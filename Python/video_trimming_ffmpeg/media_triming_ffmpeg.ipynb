{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ffmpeg-python to trim videos and audio files\n",
    "\n",
    "In this module, we will trim videos and audio files using ffmpeg-python package.\n",
    "\n",
    "### Case senarios\n",
    "**Case 1**: Imagine that you have annotated a video for co-speech manual gestures and speech. Next, you want to extract a video for each annotated gesture. How do you do it?\n",
    "\n",
    "**Case 2**: You have 60 videos from an experiment. The video starts 3-5 minutes before the trials start, and you want to trim the part before the trials. How do you do it?\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Obviously, manually trimming the videos isn't the most efficient option. But I have good news for you: **You can use Python to automate this tedious task!!** <br>\n",
    "*Case 2 requires some manual coding of timestamps, and it might be faster to manually trim the videos. So, we'll focus on Case 1 in this module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Playing with ffmpeg-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's play with ffmpeg-python package. Here, we will cut the first 60 seconds (media_start) of the video. <br>\n",
    "Before running the code, make sure to delete the output video file in the output folder if it already exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "\n",
    "media_start = 60 # seconds\n",
    "input_file_path = \"input/salma_hayek.mp4\"\n",
    "trimmed_video_file_path = \"output/salma_hayek_trimmed.mp4\"\n",
    "\n",
    "# syntax: ffmpeg.input(input_video_path, ss=start_time_in_seconds).output(output_video_path).run()\n",
    "# loglevel=\"quiet\" is used to hide the ffmpeg logs\n",
    "# c='copy' is used to copy the video stream without re-encoding\n",
    "ffmpeg.input(input_file_path, ss=media_start).output(trimmed_video_file_path, loglevel=\"quiet\", c='copy').run()\n",
    "print(\"Success! Trimmed video saved at: \", trimmed_video_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the video is trimmed properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_input = ffmpeg.probe(input_file_path)\n",
    "info_output = ffmpeg.probe(trimmed_video_file_path)\n",
    "\n",
    "#print duration of videos in seconds\n",
    "print(f\"Input video duration: {info_input['format']['duration']}\")\n",
    "print(f\"Output video duration: {info_output['format']['duration']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color = 'orange'>Exercise</font>\n",
    "\n",
    "Trim the same video from 00:00:30 to 00:01:30 (so the video will be 60 seconds long)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_video_file_path = \"output/salma_hayek_exercise.mp4\"\n",
    "\n",
    "### write the rest of the code here ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for tips</summary>\n",
    "\n",
    "In ffmpeg.input(), we used **ss** paramter for start time, and we can use **to** to specify until which point in the video we want to keep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here for solution</summary>\n",
    "\n",
    "```python\n",
    "trimmed_video_file_path = \"output/salma_hayek_video_exercise.mp4\"\n",
    "\n",
    "media_start = 30 #seconds\n",
    "media_end = 90\n",
    "\n",
    "ffmpeg.input(input_file_path, ss=media_start, to=media_end).output(trimmed_video_file_path, loglevel=\"quiet\", c='copy').run()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Case 1: Extracting videos for each annotated gesture\n",
    "\n",
    "In this module, we will extract video clips for each annotated gesture. The output video will be named in the format \"videoname_gesturetype_index.mp4\" and will be stored in the output folder.\n",
    "\n",
    "Let's start with importing libraries and specifying folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import ffmpeg # ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Folders\n",
    "video_folder = \"input\"\n",
    "annot_folder = os.path.join(video_folder, \"elan\")\n",
    "output_folder = \"output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write \"extract_video\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video(video, df_annot):\n",
    "    # initiate counter variables for each gesture type\n",
    "    iconic_counter = 0\n",
    "    metaphoric_counter = 0\n",
    "    deictic_counter = 0\n",
    "    beat_counter = 0\n",
    "    annot_index = \"\"\n",
    "\n",
    "    # get the video file name\n",
    "    video_file_name = os.path.basename(video)\n",
    "\n",
    "    # loop through the dataframe and get start and end time for each annotation (row)\n",
    "    for index, row in df_annot.iterrows():\n",
    "        # get start and end time\n",
    "        start_time = row['Begin Time - msec'] / 1000 # convert to seconds\n",
    "        end_time = row['End Time - msec'] / 1000 # convert to seconds\n",
    "        # get the annotation text foe gesture_type tier\n",
    "        annot_text = row['gesture_type']\n",
    "        \n",
    "        # check the annotation text and update the counter variable\n",
    "        if annot_text == \"iconic\":\n",
    "            iconic_counter += 1\n",
    "            annot_index = annot_text + \"_\" + str(iconic_counter)\n",
    "        elif annot_text == \"metaphoric\":\n",
    "            metaphoric_counter += 1\n",
    "            annot_index = annot_text + \"_\" +  str(metaphoric_counter)\n",
    "        elif annot_text == \"deictic\":\n",
    "            deictic_counter += 1\n",
    "            annot_index = annot_text + \"_\" +  str(deictic_counter)\n",
    "        elif annot_text == \"beat\":\n",
    "            beat_counter += 1\n",
    "            annot_index = annot_text + \"_\" +  str(beat_counter)\n",
    "\n",
    "        # create the output file name\n",
    "        output_file_name = video_file_name + \"_\" + annot_index + \".mp4\"\n",
    "        # create the output file path\n",
    "        output_file_path = os.path.join(output_folder, output_file_name)\n",
    "        \n",
    "        # check if the output file already exists\n",
    "        if not os.path.exists(output_file_path):\n",
    "            # trim the video\n",
    "            ffmpeg.input(video, ss=start_time, to=end_time).output(output_file_path, loglevel=\"quiet\", c='copy').run()\n",
    "\n",
    "    return iconic_counter, metaphoric_counter, deictic_counter, beat_counter, video_file_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through each elan annotation file and run the \"extract_video\" function\n",
    "*The name of video files and annotation files must be identical except for the extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_files = [f for f in os.listdir(annot_folder) if f.endswith('.txt')]\n",
    "print(annot_files)\n",
    "\n",
    "for annot_file in annot_files:\n",
    "    annot_file_path = os.path.join(annot_folder, annot_file)\n",
    "    video_file_path = os.path.join(video_folder, annot_file.replace(\".txt\", \".mp4\"))\n",
    "\n",
    "    df_annot = pd.read_csv(annot_file_path, sep=\"\\t\")\n",
    "    iconic, metaphoric, deictic, beat, video_file_name = extract_video(video_file_path, df_annot)\n",
    "    print(f\"Video file: {video_file_name} --> Exported videos for {iconic} iconic, {metaphoric} metaphoric, {deictic} deictic, and {beat} beat gestures.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sho",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
